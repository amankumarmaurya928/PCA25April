{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2068549-db82-42a6-91b7-fdb6ceb5bc94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Eigenvalues are the special set of scalar values that is associated with the set of linear equations most probably in \\n   the matrix equations. The eigenvectors are also termed as characteristic roots. It is a non-zero vector that can be\\n   changed at most by its scalar factor after the application of linear transformations.\\n   In simple terms, eigenvalues and eigenvectors are the building blocks of linear transformations. Eigenvalues represent\\n   the scaling factor by which a vector is transformed when a linear transformation is applied, while eigenvectors \\n   represent the directions in which the transformation occurs.\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q1\n",
    "'''Eigenvalues are the special set of scalar values that is associated with the set of linear equations most probably in \n",
    "   the matrix equations. The eigenvectors are also termed as characteristic roots. It is a non-zero vector that can be\n",
    "   changed at most by its scalar factor after the application of linear transformations.\n",
    "   In simple terms, eigenvalues and eigenvectors are the building blocks of linear transformations. Eigenvalues represent\n",
    "   the scaling factor by which a vector is transformed when a linear transformation is applied, while eigenvectors \n",
    "   represent the directions in which the transformation occurs.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9472cc7-26ea-420f-b161-a99068701ffc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In linear algebra, eigendecomposition is the factorization of a matrix into a canonical form, whereby the matrix is\\n   represented in terms of its eigenvalues and eigenvectors. Only diagonalizable matrices can be factorized in this way.\\n   Eigendecomposition provides us with a tool to decompose a matrix by discovering the eigenvalues and the eigenvectors.\\n\\n   This operation can prove useful since it allows certain matrix operations to be easier to perform and it also tells us\\n   important facts about the matrix itself. \\n   For example, a matrix is only singular if any eigenvalues are zero.\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q2\n",
    "'''In linear algebra, eigendecomposition is the factorization of a matrix into a canonical form, whereby the matrix is\n",
    "   represented in terms of its eigenvalues and eigenvectors. Only diagonalizable matrices can be factorized in this way.\n",
    "   Eigendecomposition provides us with a tool to decompose a matrix by discovering the eigenvalues and the eigenvectors.\n",
    "\n",
    "   This operation can prove useful since it allows certain matrix operations to be easier to perform and it also tells us\n",
    "   important facts about the matrix itself. \n",
    "   For example, a matrix is only singular if any eigenvalues are zero.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df41d18d-3640-41a3-9812-4443e286f56f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Diagonalizable matrices and maps are of interest because diagonal matrices are especially easy to handle:\\n   their eigenvalues and eigenvectors are known and one can raise a diagonal matrix to a power by simply\\n   raising the diagonal entries to that same power. Geometrically, a diagonalizable matrix is an inhomogeneous\\n   dilation (or anisotropic scaling) — it scales the space, as does a homogeneous dilation, but by a different\\n   factor in each direction, determined by the scale factors on each axis (diagonal entries).\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q3\n",
    "'''Diagonalizable matrices and maps are of interest because diagonal matrices are especially easy to handle:\n",
    "   their eigenvalues and eigenvectors are known and one can raise a diagonal matrix to a power by simply\n",
    "   raising the diagonal entries to that same power. Geometrically, a diagonalizable matrix is an inhomogeneous\n",
    "   dilation (or anisotropic scaling) — it scales the space, as does a homogeneous dilation, but by a different\n",
    "   factor in each direction, determined by the scale factors on each axis (diagonal entries).\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "889b1389-6a39-4d54-9b3e-e642704bfa39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The spectral theorem provides a sufficient criterion for the existence of a particular canonical form. Specifically, the \\n   spectral theorem states that if M equals the transpose of M, then M is diagonalizable: there exists an invertible matrix C\\n   such that C − 1 M C C^{-1} MC C−1MC is a diagonal matrix.\\n   In linear algebra, eigendecomposition is the factorization of a matrix into a canonical form, whereby the matrix is \\n   represented in terms of its eigenvalues and eigenvectors. Only diagonalizable matrices can be factorized in this way.\\n   Example\\nThe 2 × 2 real matrix A\\n       =[1  0\\n         1  3]\\n       may be decomposed into a diagonal matrix through multiplication of a non-singular matrix B\\n        =[5  2\\n          4   3]\\n       2×2\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q4\n",
    "'''The spectral theorem provides a sufficient criterion for the existence of a particular canonical form. Specifically, the \n",
    "   spectral theorem states that if M equals the transpose of M, then M is diagonalizable: there exists an invertible matrix C\n",
    "   such that C − 1 M C C^{-1} MC C−1MC is a diagonal matrix.\n",
    "   In linear algebra, eigendecomposition is the factorization of a matrix into a canonical form, whereby the matrix is \n",
    "   represented in terms of its eigenvalues and eigenvectors. Only diagonalizable matrices can be factorized in this way.\n",
    "   Example\n",
    "The 2 × 2 real matrix A\n",
    "       =[1  0\n",
    "         1  3]\n",
    "       may be decomposed into a diagonal matrix through multiplication of a non-singular matrix B\n",
    "        =[5  2\n",
    "          4   3]\n",
    "       2×2\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a66a812-d2fd-4b26-bfd6-ab5fd56d7928",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'To find the eigenvalues of a square matrix A: Find its characteristic equation using |A - λI| = 0, where I is the identity\\n   matrix of same order A. Solve it for λ and the solutions would give the eigenvalues.\\n   Eigenvalues represent the scaling factor by which a vector is transformed when a linear transformation is applied, while \\n   eigenvectors represent the directions in which the transformation occurs.\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q5\n",
    "'''To find the eigenvalues of a square matrix A: Find its characteristic equation using |A - λI| = 0, where I is the identity\n",
    "   matrix of same order A. Solve it for λ and the solutions would give the eigenvalues.\n",
    "   Eigenvalues represent the scaling factor by which a vector is transformed when a linear transformation is applied, while \n",
    "   eigenvectors represent the directions in which the transformation occurs.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1fa15523-9e7d-431a-ae84-bd2368c128d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'An eigenvector corresponds to the real non zero eigenvalues which point in the direction stretched by the transformation \\n   whereas eigenvalue is considered as a factor by which it is stretched. In case, if the eigenvalue is negative, the \\n   direction of the transformation is negative.\\n    eigenvalues and eigenvectors are the building blocks of linear transformations. Eigenvalues represent the scaling factor\\n    by which a vector is transformed when a linear transformation is applied, while eigenvectors represent the directions in \\n    which the transformation occurs.\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q6\n",
    "'''An eigenvector corresponds to the real non zero eigenvalues which point in the direction stretched by the transformation \n",
    "   whereas eigenvalue is considered as a factor by which it is stretched. In case, if the eigenvalue is negative, the \n",
    "   direction of the transformation is negative.\n",
    "    eigenvalues and eigenvectors are the building blocks of linear transformations. Eigenvalues represent the scaling factor\n",
    "    by which a vector is transformed when a linear transformation is applied, while eigenvectors represent the directions in \n",
    "    which the transformation occurs.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f66fb48e-c79f-4322-9128-f18bbb8acc40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Geometrically, an eigenvector, corresponding to a real nonzero eigenvalue, points in a direction in which it is stretched\\n   by the transformation and the eigenvalue is the factor by which it is stretched. If the eigenvalue is negative, the \\n   direction is reversed.\\n   The eigenvectors and eigenvalues of a covariance (or correlation) matrix represent the “core” of a PCA: The eigenvectors \\n   (principal components) determine the directions of the new feature space, and the eigenvalues determine their magnitude.\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q7\n",
    "'''Geometrically, an eigenvector, corresponding to a real nonzero eigenvalue, points in a direction in which it is stretched\n",
    "   by the transformation and the eigenvalue is the factor by which it is stretched. If the eigenvalue is negative, the \n",
    "   direction is reversed.\n",
    "   The eigenvectors and eigenvalues of a covariance (or correlation) matrix represent the “core” of a PCA: The eigenvectors \n",
    "   (principal components) determine the directions of the new feature space, and the eigenvalues determine their magnitude.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a87b8c2e-728a-4508-80f6-286e01396050",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'It is used in car design especially car stereo system and also in decoupling three phase system. Eigendecomposition is\\n   particularly useful for analysing the structure of the data matrix in terms of the eigenvalues and eigenvectors.\\n   Eigendecomposition provides us with a tool to decompose a matrix by discovering the eigenvalues and the eigenvectors. This\\n   operation can prove useful since it allows certain matrix operations to be easier to perform and it also tells us important \\n   facts about the matrix itself.\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q8\n",
    "'''It is used in car design especially car stereo system and also in decoupling three phase system. Eigendecomposition is\n",
    "   particularly useful for analysing the structure of the data matrix in terms of the eigenvalues and eigenvectors.\n",
    "   Eigendecomposition provides us with a tool to decompose a matrix by discovering the eigenvalues and the eigenvectors. This\n",
    "   operation can prove useful since it allows certain matrix operations to be easier to perform and it also tells us important \n",
    "   facts about the matrix itself.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b4c4c9a3-bc03-4a6e-943b-9187f993e1e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Since a nonzero subspace is infinite, every eigenvalue has infinitely many eigenvectors. (For example, multiplying an \\n   eigenvector by a nonzero scalar gives another eigenvector.) On the other hand, there can be at most n linearly independent \\n   eigenvectors of an n × n matrix, since R n has dimension n .\\n   If a matrix has more than one eigenvector the associated eigenvalues can be different for the different eigenvectors. \\n   Geometrically, the action of a matrix on one of its eigenvectors causes the vector to stretch (or shrink) and/or reverse \\n   direction. So, 0=Av-kv=Av-kIv=(A-kI)v.\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q9\n",
    "'''Since a nonzero subspace is infinite, every eigenvalue has infinitely many eigenvectors. (For example, multiplying an \n",
    "   eigenvector by a nonzero scalar gives another eigenvector.) On the other hand, there can be at most n linearly independent \n",
    "   eigenvectors of an n × n matrix, since R n has dimension n .\n",
    "   If a matrix has more than one eigenvector the associated eigenvalues can be different for the different eigenvectors. \n",
    "   Geometrically, the action of a matrix on one of its eigenvectors causes the vector to stretch (or shrink) and/or reverse \n",
    "   direction. So, 0=Av-kv=Av-kIv=(A-kI)v.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6bb84d61-2d9d-4335-9356-09aa096e0fb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Eigendecomposition provides us with a tool to decompose a matrix by discovering the eigenvalues and the eigenvectors. This\\n   operation can prove useful since it allows certain matrix operations to be easier to perform and it also tells us important\\n   facts about the matrix itself.\\n   Eigenvalues and eigenvectors are used for: Computing prediction and confidence ellipses. Principal Components Analysis \\n   (later in the course) Factor Analysis (also later in this course)\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q10\n",
    "'''Eigendecomposition provides us with a tool to decompose a matrix by discovering the eigenvalues and the eigenvectors. This\n",
    "   operation can prove useful since it allows certain matrix operations to be easier to perform and it also tells us important\n",
    "   facts about the matrix itself.\n",
    "   Eigenvalues and eigenvectors are used for: Computing prediction and confidence ellipses. Principal Components Analysis \n",
    "   (later in the course) Factor Analysis (also later in this course)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a7b202-10c6-49d2-9e16-c86a91d80e09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
